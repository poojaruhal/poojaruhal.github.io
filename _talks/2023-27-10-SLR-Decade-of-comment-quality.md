---
title: "A Decade of Code Comment Quality Assessment: A Systematic Literature Review"
collection: talks
type: "Presentation"
permalink: /talks/2023-27-10-SLR-Decade-of-comment-quality 
venue: " Empirical Software Engineering and Measurement (ESEM)"
date: 2023-10-27
location: "New Orleans, USA"
---

[Slides](https://poojaruhal.github.io/files/Slides-Decade-of-comment-quality-assessment.pdf)

[Online](https://www.slideshare.net/PoojaRuhal/a-decade-of-comment-quality-assessment-a-systematic-literature-review-1398)

[Event Details](https://conf.researchr.org/home/esem-2023)

Code comments are important artifacts in software systems and play a paramount role in many software engineering (SE) tasks related to maintenance and program comprehension. However, while it is widely accepted that high quality matters in code comments just as it matters in source code, assessing comment quality in practice is still an open problem. First and foremost, there is no unique definition of quality when it comes to evaluating code comments. In this paper, we present a Systematic Literature Review (SLR) of the last decade of research in SE. Our evaluation, based on the analysis of 2353 papers and the actual review of 47 relevant ones, shows that (i) most studies and techniques focus on comments in Java code, thus may not be generalizable to other languages, and (ii) the analyzed studies focus on four main QAs of a total of 21 QAs identified in the literature, with a clear predominance of checking consistency between comments and the code. We observe that researchers rely on manual assessment and specific heuristics rather than the automated assessment of the comment quality attributes, with evaluations often involving surveys of students and the authors of the original studies but rarely professional developers.